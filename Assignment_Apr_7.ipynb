{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad43f18",
   "metadata": {},
   "source": [
    "Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "\n",
    "\n",
    "Polynomial functions are a class of functions that can be used to model data. They are functions that consist of one or more terms, where each term is a product of a coefficient and a variable raised to a power. For example, a quadratic polynomial function can be written as f(x) = ax^2 + bx + c.\n",
    "\n",
    "Kernel functions, on the other hand, are mathematical functions that are used to measure the similarity between pairs of data points. They are commonly used in machine learning algorithms such as support vector machines (SVMs) and kernel regression.\n",
    "\n",
    "In some cases, polynomial functions can be used as kernel functions in SVMs. This is because SVMs work by mapping the data points into a higher-dimensional space where they can be separated by a hyperplane. One way to do this is to use a polynomial function to transform the data into a higher-dimensional space. The resulting kernel function is called a polynomial kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a159427",
   "metadata": {},
   "source": [
    "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c966d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929d56c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data to work with using make_classification() function:\n",
    "x,y=make_classification(n_samples=1000,n_features=3,n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b77e060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9319c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVC class and set the kernel to \"poly\" for polynomial kernel,\n",
    "# and other relevant parameters:\n",
    "\n",
    "svc_poly=SVC(kernel='poly',degree=3,coef0=1,C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66d32edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, coef0=1, kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model:\n",
    "svc_poly.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c881781a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred=svc_poly.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcfbdf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "Precision: 0.88\n",
      "Recall: 0.8627450980392157\n",
      "F1-Score: 0.8712871287128714\n"
     ]
    }
   ],
   "source": [
    "# Evalaute:\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caacbb8",
   "metadata": {},
   "source": [
    "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "\n",
    "In support vector regression (SVR), the parameter epsilon (Îµ) determines the size of the margin around the predicted values within which no penalty is incurred for errors. Increasing the value of epsilon allows for larger errors to be tolerated, resulting in a wider margin and potentially fewer support vectors.\n",
    "\n",
    "The number of support vectors in SVR depends on the complexity of the data and the value of the regularization parameter C. As the value of epsilon is increased, the model may be less likely to penalize errors that fall within the margin, leading to fewer support vectors being selected. However, this effect may be counteracted by increasing the value of C, which increases the penalty for errors and can result in more support vectors being selected.\n",
    "\n",
    "In general, the relationship between the value of epsilon and the number of support vectors in SVR is complex and depends on the specific dataset and model parameters. However, increasing the value of epsilon can sometimes lead to a reduction in the number of support vectors, as long as the errors within the margin are not too large relative to the size of the margin and the value of C is not too small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5647539",
   "metadata": {},
   "source": [
    "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "\n",
    "Kernel function: The kernel function determines how the input data is transformed into a higher-dimensional space, where a linear decision boundary can be used to separate the data. The choice of kernel function can greatly affect the performance of the model. For example, a radial basis function (RBF) kernel may work well for data with complex nonlinear relationships, while a linear kernel may work well for data with a linear relationship.\n",
    "\n",
    "C parameter: The C parameter controls the tradeoff between maximizing the margin and minimizing the classification error. A large value of C will result in a smaller margin and more errors, while a small value of C will result in a larger margin and fewer errors. Increasing C can lead to overfitting, while decreasing C can lead to underfitting.\n",
    "\n",
    "Epsilon parameter: The epsilon parameter determines the size of the margin around the predicted values within which no penalty is incurred for errors. Increasing the value of epsilon allows for larger errors to be tolerated, resulting in a wider margin and potentially fewer support vectors. Decreasing the value of epsilon will result in a smaller margin and more support vectors.\n",
    "\n",
    "Gamma parameter: The gamma parameter determines the width of the Gaussian kernel and affects the shape of the decision boundary. A small value of gamma will result in a smoother decision boundary, while a large value of gamma will result in a more complex decision boundary. A high value of gamma can lead to overfitting, while a low value of gamma can lead to underfitting.\n",
    "\n",
    "Examples of when you might want to increase or decrease each parameter:\n",
    "\n",
    "Kernel function: If the data has a linear relationship, a linear kernel may work well. If the data has a complex nonlinear relationship, an RBF kernel may work better.\n",
    "\n",
    "C parameter: If the model is overfitting, you might want to decrease the value of C to increase the margin and reduce the number of support vectors. If the model is underfitting, you might want to increase the value of C to reduce the margin and increase the number of support vectors.\n",
    "\n",
    "Epsilon parameter: If you want to allow for larger errors, you might want to increase the value of epsilon to widen the margin. If you want to reduce the number of support vectors, you might want to increase the value of epsilon.\n",
    "\n",
    "Gamma parameter: If the model is overfitting, you might want to decrease the value of gamma to smooth the decision boundary. If the model is underfitting, you might want to increase the value of gamma to make the decision boundary more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f088ef0f",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Import the necessary libraries and load the dataset\n",
    "Split the dataset into training and testing sets\n",
    "Preprocess the data using any technique of your choice (e.g. scaling, normalization)\n",
    "Create an instance of the SVC classifier and train it on the training data\n",
    "hse the trained classifier to predict the labels of the testing data\n",
    "Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score)\n",
    "Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to improve its performance\n",
    "Train the tuned classifier on the entire dataset\n",
    "Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a852ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518c775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data=load_breast_cancer()\n",
    "x=data.data\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329253db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db793802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1543d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing set\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928af247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train_scaled=scaler.fit_transform(x_train)\n",
    "x_test_scaled=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7043256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.44075296, -0.43531947, -1.36208497, ...,  0.9320124 ,\n",
       "         2.09724217,  1.88645014],\n",
       "       [ 1.97409619,  1.73302577,  2.09167167, ...,  2.6989469 ,\n",
       "         1.89116053,  2.49783848],\n",
       "       [-1.39998202, -1.24962228, -1.34520926, ..., -0.97023893,\n",
       "         0.59760192,  0.0578942 ],\n",
       "       ...,\n",
       "       [ 0.04880192, -0.55500086, -0.06512547, ..., -1.23903365,\n",
       "        -0.70863864, -1.27145475],\n",
       "       [-0.03896885,  0.10207345, -0.03137406, ...,  1.05001236,\n",
       "         0.43432185,  1.21336207],\n",
       "       [-0.54860557,  0.31327591, -0.60350155, ..., -0.61102866,\n",
       "        -0.3345212 , -0.84628745]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b69b74d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46649743, -0.13728933, -0.44421138, ..., -0.19435087,\n",
       "         0.17275669,  0.20372995],\n",
       "       [ 1.36536344,  0.49866473,  1.30551088, ...,  0.99177862,\n",
       "        -0.561211  , -1.00838949],\n",
       "       [ 0.38006578,  0.06921974,  0.40410139, ...,  0.57035018,\n",
       "        -0.10783139, -0.20629287],\n",
       "       ...,\n",
       "       [-0.73547237, -0.99852603, -0.74138839, ..., -0.27741059,\n",
       "        -0.3820785 , -0.32408328],\n",
       "       [ 0.02898271,  2.0334026 ,  0.0274851 , ..., -0.49027026,\n",
       "        -1.60905688, -0.33137507],\n",
       "       [ 1.87216885,  2.80077153,  1.80354992, ...,  0.7925579 ,\n",
       "        -0.05868885, -0.09467243]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be717bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the SVC classifier and train it on the training data\n",
    "svc=SVC()\n",
    "svc.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd16d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred=svc.predict(x_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe93b5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9824561403508771\n",
      "Precision: 0.9726027397260274\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of the classifier \n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55979c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune the hyperparameters using GridSearchCV\n",
    "parameters={\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce98604",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(SVC(),param_grid=parameters,scoring='accuracy',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8eb77d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17eed3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'kernel': 'rbf'}\n",
      "Best accuracy: 0.9758241758241759\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(f'Best hyperparameters: {grid_search.best_params_}')\n",
    "print(f'Best accuracy: {grid_search.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1ca3947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned classifier on the entire dataset\n",
    "svc_tuned = SVC(**grid_search.best_params_)\n",
    "svc_tuned.fit(scaler.transform(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70f8ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained classifier to a file for future use\n",
    "with open('svc_tuned.pickle', 'wb') as f:\n",
    "    pickle.dump(svc_tuned, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171e29ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
